%!TEX root = ../thesis.tex

\chapter{Characterising SDE linearisations: the numerics}\label{ch:linear_numerics}
We now provide numerical validation of the results in \Cref{ch:linear_theory} on four different example stochastic differential equations in 1-, 2-, and 3-dimensions.
A majority of the content in this chapter again appears in the submitted article \citep{BlakeEtAl_2023_ConvergenceStochasticDifferential}.
However, the overview in \Cref{sec:mazzoni} of an algorithm \citep{Mazzoni_2008_ComputationalAspectsContinuous} for efficiently solving the mean-covariance equations for the linearisation approximation and \Cref{sec:comput_s2_3d}, where we provide an example of stochastic sensitivity computed for a 3-dimensional system, do not appear in the submitted article.

\section{The Mazzoni method}\label{sec:mazzoni}
\td{Update equation references! Relate to stuff in the paper, not the later chapter!!}
In \Cref{cor:limit_moments}, we established expressions for the first two moments of the solution \(l_t^{(\epsilon)}\) of the solution \(l_t^{(\epsilon)}\) to the linearisation \cref{eqn:linear_sde_inform} of the SDE \cref{eqn:sde_y}.
When the initial condition of the SDE is fixed or Gaussian---a case often used in practice and one which we restrict ourselves to in this chapter---the linearisation solution \(l_t^{(\epsilon)}\) is also Gaussian and characterised entirely by those two moments.
The mean is given by the deterministic trajectory \(F_0^t\!\left(x_0\right)\) about which \cref{eqn:sde_y} was linearised and the variance can be computed by solving the matrix differential equation \cref{eqn:pi_ode} in \Cref{rem:cov_ode}.
The deterministic trajectory \(F_0^t\!\left(x_0\right)\) is obtained by solving the deterministic equation \cref{eqn:det_ode}, so we can re-frame the computation of \(l_t^{(\epsilon)}\) as the joint solving of a pair of differential equations.
Suppose that the initial condition \(y_0^{(\epsilon)} = l_t^{(\epsilon)}\) is Gaussian with mean \(x_0\) and covariance matrix \(\Sigma_0\).
For notational brevity, set \(w_t \coloneqq F_0^t\!\left(x_0\right)\) and \(\Pi_t \coloneqq \var{l_t}\), so that at any time \(t\)
\[
	l_t^{(\epsilon)} \isGauss{w_t, \, \Pi_t}.
\]
We can then compute \(w_t\) and \(\Pi_t\) by solving the system of ordinary differential equation
\begin{subequations}\label{eqn:gauss_de}
	\begin{align}
		\dod{w_t}{t}   & = u\!\left(w_t, t\right), \quad w_0 = x_0 \label{eqn:gauss_mean_de}                                                                                                                    \\
		\dod{\Pi_t}{t} & = \begin{multlined}[t]
			                   \nabla u\!\left(w_t, t\right) \Pi_t + \Pi_t\left[\nabla u\left(w_t, t\right)\right]^{\T} + \epsilon \sigma\left(w_t, t \right)\sigma\left(w_t, t\right)^{\T}, \quad \Pi_0 = \Sigma_0.
		                   \end{multlined}
		\label{eqn:gauss_cov_de}
	\end{align}
\end{subequations}
where \cref{eqn:gauss_mean_de} is \cref{eqn:det_ode} and \cref{eqn:gauss_cov_de} comes from \cref{eqn:pi_ode}.
Solving \cref{eqn:gauss_de} jointly can provide a more convenient computation to obtain the distribution of the linearisation solution in practice than evaluating \cref{eqn:mean_expl_eqn} and \cref{eqn:pi_expl_eqn} directly.

An important consideration  when solving \cref{eqn:gauss_de} numerically is that \(\Pi_t\) represents a covariance matrix and must remain symmetric and positive semi-definite.
However, many standard numerical ODE schemes do not take this into account, so a specialised scheme is required.
Similar equations of the form \cref{eqn:gauss_de} (although often without explicit dependence on both time and the state in the \(\sigma\) term) are solved numerically in other applications, notably when implementing the extended Kalman filter \citep{Jazwinski_2014_StochasticProcessesFiltering, KulikovaKulikov_2014_AdaptiveODESolvers}.
\citet{KulikovaKulikov_2014_AdaptiveODESolvers} identify that that the two most significant sources of numerical error when solving equations of this form are a) the estimate of the covariance matrix \(\Sigma_s^t\) violating the requirement of positive semi-definiteness, and b) local error propagation in the state equation.
Moreover, a computationally efficient algorithm is critical to ensure that the linearisation approximation has an advantage over bulk Monte Carlo simulation.

\citet{Mazzoni_2008_ComputationalAspectsContinuous} proposes an efficient hybrid method for solving \cref{eqn:gauss_de} which addresses both difficulties a) and b) and takes advantage of the availability of the Jacobian \(\nabla u\).
This method, which we shall term the Mazzoni method, combines a Taylor-Heun approximation for \cref{eqn:gauss_mean_de} and a Gauss-Legendre step for \cref{eqn:gauss_cov_de}.
With a step size of \(\delta \tau\), integration for both the state variable and the covariance matrix are convergent with order \(\mathcal{O}\!\left(\delta \tau^2\right)\).
Moreover, \citet{Mazzoni_2008_ComputationalAspectsContinuous} shows through numerical simulations that the algorithm is computationally efficient when compared to alternatives with moderate precision, and since the algorithm relies on matrix operations, it scales well with the dimension of the model.
We therefore employ the Mazzoni method for all subsequent computations of the linearisation solution.

\begin{figure}
	\begin{center}

		\begin{tikzpicture}[node distance=70pt]
			\tikzstyle{arrow} = [->,>=stealth]

			\node (s) [rectangle, rounded corners, draw=black, align=center] {\textbf{Start} \\ Given \(t, x_0, \Sigma_0\) \\ Specify \(\delta \tau_{\mathrm{min}}, \beta, \gamma\)};

			\node (a) [rectangle, below of=s, draw=black, align=center, yshift=-10pt] {Set \(\tau_0 = 0\) \\ Set \(w_{\tau_0} = x_0\) \\ Set \(\Pi_{\tau_0} = \Sigma_0\) Set \(\delta \tau = \delta \tau_{\mathrm{min}}\) \\ Set \(k = 0\)};
			\node (b) [rectangle, below of=a, draw=black, align=center, yshift=-20pt] {Set \(\tau_{k+1} = \tau_k + \delta \tau\) \\ Compute \(w_{\tau_{k+1}}\) with \cref{eqn:mazzoni_state_update} \\
				Compute \(e\) with \cref{eqn:mazzoni_e} \\ Set \(\delta \tau_{\mathrm{new}} = \max\left\{\delta \tau_{\mathrm{min}}, \beta \delta \tau \sqrt{\frac{\gamma}{\hat{\gamma}}}\right\}\)};

			\node (d) [diamond, below of=b, draw=black, align=center, yshift=-40pt] {\(\hat{\gamma} \leq \gamma\) or \\ \(\delta \tau \leq \delta \tau_{\mathrm{min}}\)?};
			\node (c) [rectangle, left of=d, draw=black, align=center, xshift=-75pt] {Set \(\delta\tau = \delta \tau_{\mathrm{new}}\)};

			\node (e) [rectangle, below of=d, draw=black, align=center, yshift=-20pt] {Compute \(\Pi_{\tau_{k+1}}\) with \crefrange{eqn:mazzoni_cov_terms1}{eqn:mazzoni_cov_terms3} \\ Set \(k = k + 1\)};

			\node (f) [diamond, below of=e, draw=black, align=center] {\(\tau_k = t\)?};

			\node (g) [rectangle, rounded corners, left of=f, draw=black, align = center, xshift = -30pt] {\textbf{Stop}};
			\node (h) [rectangle, right of=f, draw=black, align = center, xshift = 75pt] {\(\delta \tau = \min\left\{\delta \tau_{\mathrm{new}}, t - \tau_k\right\}\)};

			\draw [arrow] (s) -- (a);

			\draw [arrow] (a) -- (b);
			\draw [arrow] (b) -- (d);

			\draw [arrow] (d) -- node[anchor=south] {no} (c);
			\draw [arrow] (d) -- node[anchor=east] {yes} (e);

			\draw [arrow] (c) |- (b);

			\draw [arrow] (e) -- (f);

			\draw [arrow] (f) -- node[anchor=south] {yes} (g);
			\draw [arrow] (f) -- node[anchor=south] {no} (h);

			\draw [arrow] (h) |- (b);
		\end{tikzpicture}
		\caption{A flowchart of the Mazzoni algorithm with adaptive time stepping to solve \cref{eqn:gauss_de} over the time interval \([0,t]\).
			The minimum step size \(\delta \tau_{\mathrm{min}}\) is specified and enforced to ensure that the step size does not become too small to compromise computationally efficiency.
			Recreated from Figure 2 of \citet{Mazzoni_2008_ComputationalAspectsContinuous}.}
		\label{fig:mazzoni_alg}
	\end{center}
\end{figure}

We summarise the algorithm in the following and provide a diagram of the full implementation in \Cref{fig:mazzoni_alg}.
Further details on the derivation of these equations are available in the original article \citep{Mazzoni_2008_ComputationalAspectsContinuous}.
The Taylor-Heun formula for the update of the state over the interval \([\tau, \tau + \delta \tau]\) is
\begin{subequations}\label{eqn:mazzoni_update}
	\begin{equation}
		w_{\tau + \delta \tau} \approx w_\tau + \left(I - \frac{\delta \tau}{2}\nabla u\!\left(w_\tau, \tau\right)\right)^{-1}.
		\label{eqn:mazzoni_state_update}
	\end{equation}
	The Gauss-Legendre update of the covariance matrix is
	\begin{equation}
		\Pi_{\tau + \delta \tau} \approx M_\iota \Pi_\tau M_\iota^{\T} + \delta \tau K_\iota \sigma\!\left(w_\iota,\, \tau + \frac{\delta \tau}{2}\right)\sigma\!\left(w_\iota,\, \tau + \frac{\delta \tau}{2}\right)^{\T} K_\iota^{\T},
		\label{eqn:mazzoni_cov_update}
	\end{equation}
	where
	\begin{align}
		w_\iota & = \frac12\left(w_\tau + w_{\tau + \delta \tau} - \frac{\delta \tau^2}{4}\nabla u\!\left(w_\tau, \, \tau\right) u\!\left(w_\tau, \, \tau\right)\right) \label{eqn:mazzoni_cov_terms1} \\
		K_\iota & = \left[I - \frac{\delta \tau}{2}\nabla u\!\left(w_\iota,\, \tau + \frac{\delta \tau}{2}\right)\right]^{-1}                                                                          \\
		M_\iota & = K_\iota \left[I + \frac{\delta \tau}{2}\nabla u\!\left(w_\iota,\, \tau + \frac{\delta \tau}{2}\right)\right] \label{eqn:mazzoni_cov_terms3}.
	\end{align}
	The vector \(w_\iota\) serves as an interpolation between \(w_\tau\) and \(w_{t + \delta \tau}\) for the state at time \(\tau + \delta \tau / 2\), which is used to provide a more accurate approximation of the covariance matrix.
	\citet{Mazzoni_2008_ComputationalAspectsContinuous} also provides the option of an adaptive time step to fix the numerical precision while ensuring a computationally efficient algorithm.
	The step size is adjusted by monitoring the error in the estimation of the state variable, aiming to maintain a specified tolerance level \(\gamma > 0\).
	Given the error vector \(\mathcal{E}\) of the state approximation, the maximum total-relative error is
	\begin{equation}\label{eqn:mazzoni_e}
		\hat{\gamma} = \max_{i = 1,\dots,n}\frac{\abs{\mathcal{E}^{(i)}}}{\abs{w_{\tau + \delta \tau}^{(i)}} + 1}
	\end{equation}
	where \(\mathcal{E}^{(i)}\) and \(w_{\tau + \delta \tau}^{(i)}\) denote the respective \(i\)th elements of \(\mathcal{E}\) and \(w_{\tau + \delta \tau}\).
	The resulting adjustment factor for the time step is
	\begin{equation}\label{eqn:mazzoni_step}
		\delta \tau_{\mathrm{new}} = \beta \delta \tau \sqrt{\frac{\gamma}{\hat{\gamma}}}.
	\end{equation}
	The factor \(\beta\) is a control parameter inserted to avoid frequent recalculations of the step size and is specified prior.
	\citet{Mazzoni_2008_ComputationalAspectsContinuous} suggests setting \(\beta = 0.8\).
	By again taking advantage of the availability of the Jacobian \(\nabla u\), the error vector is approximated as
	\begin{equation}\label{eqn:mazzoni_err}
		\mathcal{E} \approx \frac{\delta \tau^2}{2}\left[\frac{1}{3\delta t}\left(\nabla u\!\left(w_{\tau + \delta \tau}, \tau + \delta \tau\right) - \nabla u\!\left(w_\tau, \tau\right)\right) - \frac{1}{6}\nabla u\!\left(w_\tau, \tau\right)^2\right] u\!\left(w_\tau, \tau\right).
	\end{equation}
\end{subequations}
The set of equations \cref{eqn:mazzoni_update} describe the Mazzoni algorithm with an adaptive step size.

\section{Numerical validation \& examples}\label{sec:numerics}
This section will validate the theory presented in \Cref{sec:theory,sec:theory_s2}, by considering three example SDEs, each leading to a different form of the strong error bound \cref{eqn:main_ineq}.
For each example, we first demonstrate heuristically that the solution converges to the limiting distribution described by \Cref{thm:limit_sol}.
We then verify the error bound in \Cref{thm:main} directly by considering a range of values for the noise scale \(\epsilon\) and initial condition uncertainty \(\delta_r\).
In doing so, we demonstrate numerically that the form of the bound on the linearisation error predicted by \Cref{thm:main} is sharp, in the sense that estimates of the error scale exactly with the initial uncertainty \(\delta_r\) and ongoing uncertainty \(\epsilon\) as predicted.


All simulations in this section were generated using the Julia programming language \citep{BezansonEtAl_2017_JuliaFreshApproach}, with the implementations of numerical ODE and SDE solvers provided by the DifferentialEquations.jl package \citep{RackauckasNie_2017_DifferentialEquationsJlPerformant}.
The code is available at \href{https://github.com/liamblake/explicit-characterisation-sde-linearisation}{github.com/liamblake/explicit-characterisation-sde-linearisation}.




\subsection{Nonlinear dynamics, additive noise}\label{sec:numerics_nonlinear}
Consider the following SDE in 1D;
\begin{equation}\label{eqn:sine_sde}
	\dif y_t^{(\epsilon)} = \sin\!\left(y_t^{(\epsilon)}\right)\dif t + \epsilon \dif W_t.
\end{equation}
The deterministic system corresponding to \cref{eqn:sine_sde} has solution
\[
	F_0^t\!\left(x_0\right) = 2\arctan\left(e^{-t}\tan\left(\frac{x_0}{2}\right)\right).
\]
Further details of this example, including computation of the derivatives required in the linearisation, are provided in the supplementary material.

To explore the impact of initial condition uncertainty, we consider the univariate Gaussian initial condition \(y_0 = x \sim \Gauss{\mu, \rho^2}\), where the mean \(\mu\) is specified and the standard deviation \(\rho\) is a non-negative scaling parameter.
We linearise \cref{eqn:sine_sde} about the deterministic trajectory \(F_0^t\!\left(\mu\right)\) originating from the mean, that is, \(\mu\) is the chosen reference point.
This ensures that for any \(r \geq 0\)
\begin{equation}\label{eqn:num_gauss_init}
	\delta_r^r = \avg{\abs{x - \mu}^r} = M_r \rho^r.
\end{equation}
where \(M_r\) is as defined in \cref{eqn:gauss_dist_bound}.
This property of the univariate Gaussian distribution allows us to easily control the uncertainty in the initial condition and verify the bounds; by sending the parameter \(\rho\) to zero we ensure that \(\delta_r\) approaches zero also.

The linearised equation is then
\begin{equation}
	\dif l_t^{(\epsilon)} = \left[F_0^t\!\left(\mu\right) + \cos\!\left(F_0^t\!\left(\mu\right)\right)\left(l_t^{(\epsilon)} - F_0^t\!\left(\mu\right)\right)\right]\dif t + \epsilon \dif W_t, \quad l_0^{(\epsilon)} \isGauss{\mu, \rho^2}.
	\label{eqn:sine_linear}
\end{equation}
and the solution follows a Gaussian distribution, specifically
\begin{equation}\label{eqn:num_linear_sol}
	l_t^{(\epsilon)} \isGauss{F_0^t\!\left(\mu\right), \, \rho^2\nabla F_0^t\!\left(\mu\right)^2 + \epsilon^2\Sigma_0^t\!\left(\mu\right)}.
\end{equation}
where \(\Sigma_0^t\!\left(\mu\right)\) is computed by solving \cref{eqn:pi_ode} numerically subject to a zero initial condition.

In this example, we take \(\mu_0 = 0.5\) and consider the solutions of \cref{eqn:sine_sde} and \cref{eqn:sine_linear} at time \(t = 1.5\).
We generate accurate samples of \cref{eqn:sine_sde} and \cref{eqn:sine_linear} jointly (i.e.\ using the same numerical realisations of the Wiener process \(W_t\)) using the stochastic Runge-Kutta scheme SRI \citep{Rossler_2010_RungeKuttaMethodsStrong} with an adaptive step size \citep{RackauckasNie_2017_AdaptiveMethodsStochastic}.

\begin{figure}
	\begin{center}
		\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/sine/selected_hists.pdf}
		\caption{Histograms of stochastic samples of \cref{eqn:sine_sde}, subject to the Gaussian initial condition \cref{eqn:num_gauss_init}, for varying initial uncertainty scale \(\rho\) and ongoing uncertainty scale \(\epsilon\).
			The distribution of the corresponding solution \cref{eqn:num_linear_sol} to the linearised equation is overlaid in black.}
		\label{fig:sine_hists}
	\end{center}
\end{figure}

In \Cref{fig:sine_hists}, we show histograms of \(N = 10000\) samples of the solution to nonlinear SDE \cref{eqn:sine_sde} and the corresponding probability density function of the linearised solution \cref{eqn:num_linear_sol}, for different combinations of \(\epsilon\) and \(\rho\).
Even when the ongoing noise is small, the nonlinearity of the drift term means that a large initial uncertainty results in a non-Gaussian distribution.
However, in situations where both the initial and ongoing uncertainties are small, the Gaussian solution to the linearised equation provides a reasonable approximation.
In the limit of both small initial (\(\rho \to 0\)) and small ongoing (\(\epsilon \to 0\)) uncertainty (towards the bottom right), we see that the distribution of the samples approach the Gaussian density of the linearisation solution, matching the understanding that the linearisation approximation is ``reasonable'' for small noise regimes.

Since the drift term is nonlinear and the noise is additive in \cref{eqn:sine_sde}, the bound predicted by \Cref{thm:main} has the form
\[
	\avg{\norm{y_t^{(\epsilon)} - l_t^{(\epsilon)}}^r} \leq D_1\!\left(r,t, K_{\nabla u}, K_\sigma\right)\epsilon^{2r} + M_{2r}D_2\!\left(r,t, K_{\nabla u}\right)\rho^{2r}.
\]
where we have taken \(K_{\nabla\nabla u} = 1\) and \(K_{\nabla\sigma} = 0\).
To numerically validate this bound under the Gaussian initial condition \cref{eqn:num_gauss_init}, define for \(r \geq 1\) the error measure
\begin{equation}
	E_r\!\left(\epsilon, \rho\right) \coloneqq \frac{1}{N}\sum_{i=1}^N{\norm{\hat{y}_{i}^{(\epsilon)} - \hat{l}_i^{(\epsilon)}}^r},
	\label{eqn:strong_err_mc_estimate}
\end{equation}
which is a Monte Carlo estimator of the right-hand side of \cref{eqn:main_ineq}, where \(\hat{y}_1^{(\epsilon)},\dotsc, \hat{y}_N^{(\epsilon)}\) and \(\hat{l}_1^{(\epsilon)},\dotsc, \hat{l}_N^{(\epsilon)}\) are \(N\) numerical samples of the solutions to SDE \cref{eqn:sde_y} and the linearisation \cref{eqn:linear_sde_inform} respectively.

\begin{figure}
	\begin{center}
		\begin{subfigure}{\textwidth}
			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/sine/str_err_eps_r_1.0_log.pdf}
			\caption{Estimates of the strong error (with \(r = 1\)) in linearising \cref{eqn:sine_sde} with \cref{eqn:sine_linear}, for varying ongoing uncertainty parameter \(\epsilon\).
				Each colour corresponds to a different value of the initial uncertainty parameter \(\rho\).
				A (least squares) line of best fit of the form \(\beta_0 + \beta_1 \epsilon^2\) is included in the corresponding colour.}
			\label{fig:sine_eps_lines}
		\end{subfigure}
		\begin{subfigure}{\textwidth}
			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/sine/str_err_rho_r_1.0_log.pdf}
			\caption{Estimates of the strong error (with \(r = 1\)) for varying initial uncertainty parameter \(\rho\).
				Each colour corresponds to a different value of the ongoing uncertainty parameter \(\epsilon\).
				A (least squares) line of best fit of the form \(\beta_0 + \beta_1 \rho^2\) is included in the corresponding colour.}
			\label{fig:sine_delta_lines}
		\end{subfigure}
		\caption{Validation of the theoretical bound predicted by \Cref{thm:main}, when \(r = 1\), on numerical realisations of the solution to the 1D example \cref{eqn:sine_sde}.}
		\label{fig:sine_delta_eps_lines}
	\end{center}
\end{figure}

We directly validate the \emph{form} of the error bound (as a function of \(\epsilon\) and \(\rho\)) in \Cref{fig:sine_delta_eps_lines}, by computing \(E_1\) using samples for each pair of \(\epsilon\) and \(\rho\) values.
In \Cref{fig:sine_eps_lines}, we demonstrate the relationship between \(E_1\) and the ongoing uncertainty \(\epsilon\) for several different fixed values of \(\rho\), each corresponding to a different colour.
A least squares estimate of a line of best fit of the form \(E_1 = \beta_0 + \beta_1 \epsilon^2 \), for fixed coefficients \(\beta_0\) and \(\beta_1\), is fitted to the observed errors (in untransformed space) to verify the scaling of our bound in \Cref{thm:main}.
We see that the line of best fit accurately matches the observed values of \(E_1\), verifying that \(E_1\) is in fact scaling with \(\epsilon^2\) as predicted.
\Cref{fig:sine_delta_lines} provides a similar demonstration between \(E_1\) and the initial uncertainty \(\rho\), where now each colour corresponds to a different fixed value of \(\epsilon\).
We again fit lines of the form \(E_1 = \beta_0 + \beta_1 \rho^2\) to verify the scaling of the bound, and see that the lines match the observed values of \(E_2\).
Thus, we have also validated that \(E_1\) scales with \(\rho^2\), as expected from \Cref{thm:main}.


\subsection{Linear dynamics, multiplicative noise}\label{sec:numerics_multiplicative}
Now consider the following SDE with multiplicative noise in 1D;
\begin{equation}
	\dif y_t^{(\epsilon)} = \frac12 y_t^{(\epsilon)}\dif t + \varepsilon \cos\!\left(y_t^{(\epsilon)}\right) \dif W_t.
	\label{eqn:1d_mult}
\end{equation}
The corresponding deterministic system is linear and has solution
\begin{equation}
	F_0^t\!\left(x_0\right) = \exp\!\left(\frac{t}{2}\right) x_0,
	\label{eqn:1d_mult_det_sol}
\end{equation}
with additional details provided in the supplementary materials.
As with the previous example in \Cref{sec:numerics_nonlinear}, we take the Gaussian initial condition \cref{eqn:num_gauss_init} with variance \(\rho^2\) and linearised \cref{eqn:1d_mult} about the initial mean \(\mu\).
The linearised equation is then
\begin{equation}
	\dif l_t^{(\epsilon)} = \frac12 l_t^{(\epsilon)}\dif t + \epsilon \cos\!\left(\exp\left(\frac{t}{2}\right)\mu\right) \dif W_t, \quad l_0^{(\epsilon)} \sim \Gauss{\mu, \rho^2},
	\label{eqn:1d_mult_linear}
\end{equation}
with Gaussian solution \cref{eqn:num_linear_sol}.
We take the initial point \(\mu = 2\) and consider the solutions at time \(t = 1\).
To generate numerical realisations of the solutions to \cref{eqn:1d_mult} and \cref{eqn:1d_mult_linear} with the same realisations of \(W_t\), we use the same set-up as in the previous example.

\begin{figure}
	\begin{center}
		\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/multiplicative/selected_hists.pdf}
		\caption{The same arrangement as \Cref{fig:sine_hists}, but for the 1D multiplicative noise SDE \cref{eqn:1d_mult}.}
		\label{fig:1d_mult_hists}
	\end{center}
\end{figure}

In \Cref{fig:1d_mult_hists}, we show histograms of \(N = 10000\) samples of the multiplicative noise SDE \cref{eqn:1d_mult} and the corresponding probability density function of the linearised solution, for different combinations of \(\epsilon\) and \(\rho\).
We again see that in the limit of both small initial and small ongoing uncertainty (towards the bottom right), we see that the distribution of the samples approach the Gaussian density of the linearisation solution.


\begin{figure}
	\begin{center}
		\begin{subfigure}{\textwidth}
			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/multiplicative/str_err_eps_r_1.0_log.pdf}
			\caption{Estimates of the strong order (with \(r = 1\)) for varying ongoing uncertainty parameter \(\epsilon\).
				Each colour corresponds to a different value of the initial uncertainty parameter \(\rho\).
				A (least squares) line of best fit of the form \(\beta_1 \epsilon + \beta_2 \epsilon^2\) is included in the corresponding colour.}
			\label{fig:multiplicative_eps_lines}
		\end{subfigure}
		\begin{subfigure}{\textwidth}
			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/multiplicative/str_err_rho_r_1.0_log.pdf}
			\caption{Estimates of the strong order (with \(r = 1\)) for varying initial uncertainty parameter \(\rho\).
				Each colour corresponds to a different value of the ongoing uncertainty parameter \(\epsilon\).
				A (least squares) line of best fit of the form \(\beta_0 + \beta_1 \rho\) is included in the corresponding colour.}
			\label{fig:multiplicative_delta_lines}
		\end{subfigure}
		\caption{Validation of the theoretical bound predicted by \Cref{thm:main}, when \(r = 1\), on numerical realisations of the solution to the 1D example \cref{eqn:1d_mult}.}
		\label{fig:multiplicative_delta_eps_lines}
	\end{center}
\end{figure}

Since the drift term is linear and the noise multiplicative in \cref{eqn:1d_mult}, the bound predicted by \Cref{thm:main} has the form
\[
	\avg{\norm{y_t^{(\epsilon)} - l_t^{(\epsilon)}}^r} \leq D_1\!\left(r,t, K_{\nabla u}, K_\sigma\right)\epsilon^{2r} + M_{r}D_3\!\left(r,t, K_{\nabla u}\right)\epsilon^r\rho^{r},
\]
where we have \(K_{\nabla\nabla u} = 0\) and \(K_{\nabla\sigma} = 1\).
In \Cref{fig:multiplicative_delta_eps_lines}, we again validate the form of this bound (for \(r = 1\); results for additional values of \(r\) are provided in the supplementary material) by approximating the left-hand side with \(E_1\) computed from realisations of the solution to \cref{eqn:1d_mult} and the linearisation \cref{eqn:1d_mult_linear}.
For each fixed value of the initial uncertainty \(\rho\), in \Cref{fig:multiplicative_eps_lines}, we fit a line of best fit of the form \(\beta_1 \epsilon + \beta_2 \epsilon^2\) to validate that the strong error scales as predicted.
Similarly, in \Cref{fig:multiplicative_eps_lines} we fit a line of best fit of the form \(\beta_0 + \beta_1 \rho\) and confirm that the linearisation error follows this scaling.


\subsection{Fixed initial condition}\label{sec:numerics_2d}
In this example, we consider a 2-dimensional model and a fixed initial condition, to validate the results presented in \Cref{sec:theory_fixed}.
Following the example in Chapter 5 of \citet{SamelsonWiggins_2006_LagrangianTransportGeophysical}, we consider an unsteady meandering jet in two dimensions, which may serve as an idealised model of geophysical Rossby waves \citep{Pierrehumbert_1991_ChaoticMixingTracer}.
The velocity field for \(y \equiv \left(y_1, y_2\right)^{\T}\) is given by
\begin{equation}
	u\!\left(y, t\right) = \begin{bmatrix}
		c - A\sin\!\left(Ky_1\right)\cos\!\left(y_2\right) + \oldepsilon_{\mathrm{mj}} l_1\sin\!\left(k_1\left(y_1 - c_1 t\right)\right)\cos\!\left(l_1 y_2\right) \\
		AK\cos\!\left(Ky_1\right)\sin\!\left(y_2\right) + \oldepsilon_{\mathrm{mj}} k_1\cos\!\left(k_1\left(y_1 - c_1t\right)\right)\sin\!\left(l_1 y_2\right)
	\end{bmatrix}.
	\label{eqn:jet_ex}
\end{equation}
The velocity field describes a kinematic travelling wave with deterministic oscillatory perturbations in a co-moving frame.
Here, \(A\) is the amplitude and \(c\) is the phase speed of the primary wave, and \(K\) is the wavenumber in the \(y_1\)-direction.
The oscillatory perturbation has amplitude \(\oldepsilon_{\mathrm{mj}}\), phase speed \(c_1\) (in the co-moving frame), and wavenumbers \(k_1\) and \(l_1\) in the \(y_1\)- and \(y_2\)-directions respectively.
Throughout, we take the parameter values \(c = 0.5\), \(A = 1\), \(K = 4\), \(l_1 = 2\), \(k_1 = 1\), \(c_1 = \pi\), and \(\oldepsilon_{\mathrm{mj}} = 0.3\).
For these values, the flow consists of a meandering jet with vortex structures within the meanders, and a chaotic zone which influences the fluid transfer between the jet and the vortices.

We introduce multiplicative noise by considering stochastic perturbations to the phase speed \(c\) and the primary amplitude \(A\), which we model with the respective components of a \(2\)-dimensional Wiener process \(W_t = \left(W_t^{(1)}, W_t^{(2)}\right)^{\T}\).
Then, we specify the diffusion term as
\begin{equation}
	\sigma\!\left(y,t\right) = \begin{bmatrix}
		1 & \sin\!\left(Ky_1\right)\cos\!\left(y_2\right)  \\
		0 & K\cos\!\left(Ky_1\right)\sin\!\left(y_2\right)
	\end{bmatrix}.
	\label{eqn:jet_ex_sigma}
\end{equation}


We consider the fixed initial condition \(x_0 = \left(0, 1\right)\) and the prediction of the model at time \(t = 1\).
We then consider a linearisation of the SDE about the deterministic trajectory \(F_0^t\!\left(x_0\right)\), where \(F_0^t\) is the deterministic flow map corresponding to the vector field \cref{eqn:jet_ex}.
To compute the Gaussian distribution \cref{eqn:linear_gauss_sol} of the linearised solution, we again solve \cref{eqn:pi_ode} numerically with initial condition \(\Sigma_0^t\!\left(x_0\right) = O\).
Specifically, \cref{eqn:pi_ode} is solved jointly with the deterministic state equation \cref{eqn:ode_det} using the hybrid method proposed by \citet{Mazzoni_2008_ComputationalAspectsContinuous}.
This hybrid method combines a Taylor-Heun approximation with a Gauss-Legendre one and ensures that the numerical solution of the covariance equation is symmetric and positive semi-definite while maintaining both accuracy and computational efficiency.

\begin{figure}
	\begin{center}
		\begin{subfigure}{0.49\textwidth}
			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/rossby/hist_0.1.pdf}
			\caption{\(\epsilon = 10^{-1}\)}
			\label{fig:y_hists_a}
		\end{subfigure}
		\begin{subfigure}{0.49\textwidth}
			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/rossby/hist_0.03162277660168379.pdf}
			\caption{\(\epsilon = 10^{-1.5}\)}
			\label{fig:y_hists_b}
		\end{subfigure}
		\begin{subfigure}{0.49\textwidth}
			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/rossby/hist_0.010000000000000002.pdf}
			\caption{\(\epsilon = 10^{-2}\)}
			\label{fig:y_hists_c}
		\end{subfigure}
		\begin{subfigure}{0.49\textwidth}
			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/rossby/hist_0.001.pdf}
			\caption{\(\epsilon = 10^{-3}\)}
			\label{fig:y_hists_d}
		\end{subfigure}
		\caption{Histograms of \(y_t^{(\epsilon)}\) from direct simulation of the SDE with drift \cref{eqn:jet_ex} and diffusivity \cref{eqn:jet_ex_sigma} subject to the fixed initial condition, for four different \(\epsilon\) values.
		Overlaid in black are contours of the Gaussian solution \cref{eqn:linear_gauss_sol} of the linearised SDE \cref{eqn:linear_sde_inform}, which correspond to the first three standard deviation levels centred at the mean \(F_0^t(x)\).
		In dashed blue are corresponding contours computed from the sample covariance matrix of the realisations.
		}
		\label{fig:y_hists}
	\end{center}
\end{figure}


\Cref{fig:y_hists} shows the resulting simulations of \(y_t^{(\epsilon)}\) for four different values of \(\epsilon\).
The realisations are binned as a histogram and bin counts are normalised, to provide an empirical estimate of the probability density function of \(y_t^{(\epsilon)}\).
Superimposed (in solid black) are the first, second and third standard-deviation contours of the probability density function of the Gaussian distribution that solves the linearised equation.
The first three standard-deviation levels of the \(2\times 2\) sample covariance matrix of the realisations of \(y_t^{(\epsilon)}\), are also overlaid (in dashed blue).
As \(\epsilon\) decreases towards \(0\), the samples increasingly resemble a Gaussian distribution, and both the mean and covariance coincide with the corresponding limits.

\begin{figure}
	\begin{center}
		\begin{subfigure}{0.49\textwidth}
			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/rossby/str_err_r_1.0.pdf}
			\caption{\(r = 1\) (mean)}
			\label{fig:gamma_z_valid_1}
		\end{subfigure}
		\begin{subfigure}{0.49\textwidth}
			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/rossby/str_err_r_2.0.pdf}
			\caption{\(r = 2\) (variance)}
			\label{fig:gamma_z_valid_2}
		\end{subfigure}
		\begin{subfigure}{0.49\textwidth}
			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/rossby/str_err_r_3.0.pdf}
			\caption{\(r = 3\) (skewness)}
			\label{fig:gamma_z_valid_3}
		\end{subfigure}
		\begin{subfigure}{0.49\textwidth}
			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/rossby/str_err_r_4.0.pdf}
			\caption{\(r = 4\) (kurtosis)}
			\label{fig:gamma_z_valid_4}
		\end{subfigure}

		\caption{Validation of \Cref{thm:main}, by plotting the sample \(r\)th raw moment distance (the error metric \(E_r(\epsilon)\)) between \(10000\) realisations of the meandering jet SDE and a corresponding linearisation, for decreasing values of \(\epsilon\).
			A line of best fit (in red) is placed on each, and the resulting slope indicated.}
		\label{fig:gamma_z_valid}
	\end{center}
\end{figure}

For a fixed initial condition, \cref{eqn:main_ineq} predicts that the expected distance between the original SDE solution and that of a linearisation satisfies
\[
	\avg{\norm{y_t^{(\epsilon)} - l_t^{(\epsilon)}}^r} \leq \left(K_{\nabla\nabla u} + K_{\nabla\sigma}\right)D_1\!\left(r,t, K_{\nabla u}, K_\sigma\right)\epsilon^{2r}.
\]
To numerically estimate the left-hand side of \cref{eqn:main_ineq}, we again use a Monte Carlo estimator;
\[
	E_r\!\left(\epsilon\right) \coloneqq \frac{1}{N}\sum_{i=1}^N{\norm{\hat{y}_i^{(\epsilon)} - \hat{l}_i^{(\epsilon)}}^r}.
\]
For \(r = 1,2,3,4\), \(E_r\!\left(\epsilon\right)\) is shown (in a logarithmic scale) for decreasing values of \(\epsilon\) in \Cref{fig:gamma_z_valid}.
\Cref{thm:main} predicts that \(\log_{10}\left(E_r\!\left(\epsilon\right)\right)\) should decay linearly with a slope greater than \(2r\) as \(\epsilon\) decreases to zero.
The least squares lines of best fit for each value of \(r\) in \Cref{fig:gamma_z_valid} show this behaviour, and are therefore consistent with \Cref{thm:main}.



\section{Computing stochastic sensitivity} \label{sec:comput_s2}
In this section, we illustrate the computability of stochastic sensitivity as described in \Cref{thm:s2_calculation}.
These computations are primarily demonstrative, so we keep the analysis of the results to a minimum and instead refer the reader to the works of \citet{Balasuriya_2020_StochasticSensitivityComputable,BadzaEtAl_2023_HowSensitiveAre,FangEtAl_2020_DisentanglingResolutionPrecision}, where stochastic sensitivity has been calculated and interpreted in context.

\subsection{In 2-dimensions}\label{sec:compute_s2_2d}

\begin{figure}
	\begin{center}
		\begin{subfigure}{\textwidth}
			\includegraphics[width=0.49\textwidth]{chp04_paper_numerics/figures/rossby/S2_zero_0.3}
			\includegraphics[width=0.49\textwidth]{chp04_paper_numerics/figures/rossby/S2_robust_0.3}
			\caption{\(\oldepsilon_{\mathrm{mj}} = 0.3\)}
			\label{fig:s2_field_0.3}
		\end{subfigure}
		\begin{subfigure}{\textwidth}
			\includegraphics[width=0.49\textwidth]{chp04_paper_numerics/figures/rossby/s2_zero_1.0}
			\includegraphics[width=0.49\textwidth]{chp04_paper_numerics/figures/rossby/s2_robust_1.0}
			\caption{\(\oldepsilon_{\mathrm{mj}} = 1.0\)}
			\label{fig:s2_field_1.0}
		\end{subfigure}
		\caption{(Left) The \(S^2\) field of the meandering jet flow \cref{eqn:jet_ex} over the time interval \([0,1]\), for two different sets of parameters with qualitatively different behaviour.
			% The \(S^2\) value for each initial condition is computed directly as the operator norm of the covariance matrix \(\Sigma_0^1\!\left(x_0\right)\), as per \cref{eqn:s2_calculation}.
			(Right) Robust sets \(\mathrm{RS}\!\left(10\right)\) extracted from the stochastic sensitivity fields, by taking the initial conditions with a stochastic sensitivity value about a threshold of \(10\).}
		\label{fig:ex_jet_s2_field}
	\end{center}
\end{figure}

We again consider the meandering jet \cref{eqn:jet_ex} with multiplicative noise described by \cref{eqn:jet_ex_sigma} and take the same choice of parameters as in \cref{sec:numerics_2d}, except for the perturbation amplitude \(\oldepsilon_{\mathrm{mj}}\), which is varied to obtain qualitatively different behaviour in the system.
For each initial condition \(x_0\) in a \(400 \times 400\) uniform grid on \(\left[0, \pi\right] \times \left[0, \pi\right]\), the \(S^2\) value is calculated by first computing (by solving \cref{eqn:gauss_cov_de}) the covariance matrix \(\Sigma_0^t\!\left(x_0\right)\) of the fixed initial condition linearisation and then taking the operator norm per \cref{eqn:s2_calculation}.
\Cref{fig:ex_jet_s2_field} shows the resulting \(S^2\) field from time \(0\) to \(t = 1\), for two different values of \(\oldepsilon_{\mathrm{mj}}\).
We also extract robust sets from each field, by highlighting in cyan on the right side of \Cref{fig:ex_jet_s2_field} those initial conditions with a stochastic sensitivity value less than the specified threshold of 10.
That is, cyan corresponds to the set
\[
	\mathrm{RS}\!\left(10\right) = \setc{x_0 \in [0,\pi] \times [0,\pi]}{S^2\!\left(x_0, t\right) < 10}.
\]
When \(\oldepsilon_{\mathrm{mj}} = 0.3\) (\Cref{fig:s2_field_0.3}), the \(S^2\) field is largest in the elongated gyre regions outside of the meandering jet, where the flow exhibits chaotic behaviour \citep{Pierrehumbert_1991_ChaoticMixingTracer} and we accordingly expect larger uncertainty due to the model dynamics.
As a region of small \(S^2\) value, the meandering jet emerges as a robust set, consisting of initial points whose eventual fate is significantly more certain than in other regions.
When \(\oldepsilon_{\mathrm{mj}} = 1.0\) (\Cref{fig:s2_field_1.0}), the deterministic flow is dominated by oscillatory perturbation, which further increases the chaotic nature of the solving trajectories and the boundaries between the gyres and the meandering jet are no longer distinguishable \citep{Crocker_2021_LagrangianCoherentData}.
Rotational eddies begin to dominate the flow and we see this reflected in the stochastic sensitivity field in \Cref{fig:s2_field_1.0}: the eddies exhibit a smaller stochastic sensitivity, as even under stochasticity trajectories, are inclined to remain within them.
The resulting robust sets consequently also highlight these eddies.

% \begin{figure}
% 	\begin{center}
% 		\begin{subfigure}{0.49\textwidth}
% 			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/rossby/S2_robust_0.3.pdf}
% 			\caption{\(\oldepsilon_{\mathrm{mj}} = 0.3\), \(R = 10\)}
% 		\end{subfigure}
% 		\begin{subfigure}{0.49\textwidth}
% 			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/rossby/S2_robust_1.0.pdf}
% 			\caption{\(\oldepsilon_{\mathrm{mj}} = 1.0\), \(R = 10\)}
% 		\end{subfigure}
% 		\caption{Robust sets extracted from the stochastic sensitivity fields in \Cref{fig:ex_jet_s2_field}, by taking the initial conditions with a stochastic sensitivity value above a specified threshold \(R\). }
% \td{Use cyan for robust sets, to be consistent with later results.}
% 		\label{fig:ex_jet_robust}
% 	\end{center}
% \end{figure}

% The stochastic sensitivity field can highlight Lagrangian coherent structures within the flow, by identifying regions of the flow with a relatively small uncertainty, as measured by a \emph{single} number for each initial condition.
% Subsets of the spatial domain corresponding to coherent structures can be extracted, e.g.\ by taking a threshold on \(S^2\) as described in the original work \citep{Balasuriya_2020_StochasticSensitivityComputable}; further examples of coherent structure extraction with stochastic sensitivity on both toy models and real data can be found in \citet{Balasuriya_2020_StochasticSensitivityComputable} and \citet{BadzaEtAl_2023_HowSensitiveAre}.
% Here, we demonstrate the extraction of coherent structures in \Cref{fig:ex_jet_robust} using a threshold of \(R\).
% The resulting subsets of the domain in cyan reflect our conclusions from the stochastic sensitivity field itself; when \(\epsilon_{\mathrm{mj}} = 0.3\) the meandering jet



% \begin{figure}
% 	\begin{center}
% 		\begin{subfigure}{0.49\textwidth}
% 			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/rossby/ftle_0.3.pdf}
% 			\caption{\(\oldepsilon_{\mathrm{mj}} = 0.3\)}
% 		\end{subfigure}
% 		\begin{subfigure}{0.49\textwidth}
% 			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/rossby/ftle_1.0.pdf}
% 			\caption{\(\oldepsilon_{\mathrm{mj}} = 1.0\)}
% 		\end{subfigure}
% 		\caption{The finite-time Lyapunov exponent field of the meandering jet flow \cref{eqn:jet_ex} over the time \([0,1]\), for two different values of \(\oldepsilon_{\mathrm{mj}}\).
% 			These fields should be compared with the corresponding stochastic sensitivity fields in \Cref{fig:ex_jet_s2_field}.}
% 	\end{center}
% 	\label{fig:ex_jet_ftle}
% \end{figure}



% In this example, the stochastic sensitivity and FTLE fields show strong similarities, supporting the claims in \Cref{sec:ftle_s2_connection} that stochastic sensitivity can be considered a generalisation of the FTLE.
% The two fields are quantifying different aspects of the flow, however, and so can show differences; such examples are available in \citet{Balasuriya_2020_StochasticSensitivityComputable} (see Figure 3.7) and \citet{BadzaEtAl_2023_HowSensitiveAre} (compare Figures 1 and 5, and Figures 11 and 15).

% To highlight the differences between the stochastic sensitivity field and the finite-time Lyapunov exponent, here we provide a brief and contrived example in which multiplicative noise has a substantial impact on the dynamical behaviour of the system.
% Following the example of \citet{BalasuriyaGottwald_2018_EstimatingStableUnstable}, consider the two-dimensional velocity field
% \begin{equation*}
% 	u\!\left(y, t\right) = \begin{bmatrix}
% 		-4y_1 + y_1^2 \\
% 		3y_2 - y_2^3
% 	\end{bmatrix},
% \end{equation*}
% To introduce multiplicative noise, we take the diffusivity
% \[
% 	\sigma\!\left(y,t\right) = \begin{bmatrix}
% 		1       & 0                                       \\
% 		y_2 - 1 & 3\sin\!\left(2\pi y_1\right)e^{-0.8y_1}
% 	\end{bmatrix},
% \]
% which in particular ensures a non-trivial spatial dependence along the stable manifold of interest.





% \begin{figure}
% 	\begin{center}
% 		\begin{subfigure}{0.49\textwidth}
% 			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/unstable/ftle.pdf}
% 			\caption{FTLE}
% 			\label{fig:s2_ftle_ftle}
% 		\end{subfigure}
% 		\begin{subfigure}{0.49\textwidth}
% 			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/unstable/S2_zero.pdf}
% 			\caption{\(S^2\) with fixed initial condition.}
% 			\label{fig:s2_ftle_ftle}
% 		\end{subfigure}		\begin{subfigure}{0.49\textwidth}
% 			\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/unstable/S2_I.pdf}
% 			\caption{\(S^2\) with standard Gaussian initial condition.}
% 			\label{fig:s2_ftle_ftle}
% 		\end{subfigure}
% 		\caption{The stochastic sensitivity and FTLE-type stretching fields for the two-dimensional}
% 		\label{fig:}
% 	\end{center}
% \end{figure}



%To briefly demonstrate that the stochastic sensitivity field and the resulting robust sets are in fact accounting for uncertainty, we consider a simpler, contrived example.
%We again take the velocity field \eqref{eqn:jet_ex} describing the meandering jet, but now assume that the ongoing stochasticity is 1-dimensional, i.e. \(m = 1\) in the notation of \Cref{ch:linear_theory}, and only acts on the \(y_1\)-component.
%That is, we are considering the stochastic model
%\[
%	\dif \begin{bmatrix}
%		y_1 \\ y_2
%	\end{bmatrix} = u\!\left(\begin{bmatrix}
%			y_1 \\ y_2
%		\end{bmatrix}, t\right)\dif t + \epsilon \begin{bmatrix}
%		S y_1 \\  0
%	\end{bmatrix} \dif W_t
%\]
%where \(W_t\) is a one-dimensional Wiener process, and \(S\) is a large constant.
%Intuitively, one would expect that the large uncertainty in the \(y_1\)-direction will result in a `smearing out' of trajectories in that direction and therefore a loss of coherence of the jet structure
%We illustrate this by computing the stochastic sensitivity field, and plotting this in \Cref{fig:jet_ex_y1_only} alongside the finite-time Lyapunov field over the same spatiotemporal region.

%\begin{figure}
%	\begin{center}
%		%
%		\begin{subfigure}{0.49\textwidth}
%			\caption{}
%		\end{subfigure}
%		\begin{subfigure}{0.49\textwidth}
%			\caption{}
%		\end{subfigure}
%		\caption{}
%		\label{fig:jet_ex_y1_only}
%	\end{center}
%\end{figure}


%This was a contrived example, but demonstrates that the stochastic sensitivity field provides further insight into the qualitative behaviour of

%Moreover, this simple example demonstrates the claim in \Cref{sec:theory_s2} that the stochastic sensitivity field can be considered a generalisation of the finite-time Lyapunov exponent, in that features of the latter are captured while additionally accounting for ongoing uncertainties.

\subsection{In 3-dimensions}\label{sec:comput_s2_3d}
In \Cref{def:ss_Rn}, we have provided a new definition for stochastic sensitivity in arbitrary dimensions, whereas previously the definition and computation \citep{Balasuriya_2020_StochasticSensitivityComputable} were limited to only two.
This is the second main contribution of this thesis and so we shall demonstrate this extension on an example toy model in 3-dimensions.
Consider the Gromeka-Arnold-Beltrami-Childress flow \citep{DombreEtAl_1986_ChaoticStreamlinesABC}:
\begin{equation}\label{eqn:gabc}
	u\!\left(y\right) = \begin{bmatrix}
		A\sin\!\left(y_3\right) + C\cos\!\left(y_2\right) \\
		B\sin\!\left(y_1\right) + A\cos\!\left(y_3\right) \\
		C\sin\!\left(y_2\right) + B\cos\!\left(y_1\right)
	\end{bmatrix},
\end{equation}
where \(A, B, C > 0\) are constants and \(y \equiv \left(y_1, y_2, y_3\right)^{\T}\).
The flow arises as an exact solution to Euler's equation and is often used as a testbed for Lagrangian analysis in 3-dimensions \citep[e.g.]{NelsonJacobs_2016_HighorderVisualizationThreedimensional,BruntonRowley_2010_FastComputationFinitetime,Haller_2001_DistinguishedMaterialSurfaces,SulmanEtAl_2013_LeavingFlatlandDiagnostics}.
We take the parameter values \(A = \sqrt{3}\), \(B = \sqrt{2}\), and \(C = 1\), for which the flow is spatially periodic in the cube \([0,2\pi] \times [0,2\pi] \times [0,2\pi]\)..
The flow then consists of a network of vortex structures and homoclinic orbits that cause distinct regions of `order' and chaos to emerge \citep{DombreEtAl_1986_ChaoticStreamlinesABC}.

% \td{Only include one plot - analyse the 3D structure with slices}
% \begin{figure}
% 	\centering
% 	% \begin{subfigure}[t]{0.49\textwidth}
% 	% 	\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/gabc/S2_box_1.7320508075688772_1.4142135623730951_0_cropped}
% 	% 	% \includegraphics[width=0.49\textwidth]{chp04_paper_numerics/figures/gabc/robust_box_1}
% 	% 	\caption{\(C = 0\)}
% 	% 	\label{fig:gabc_S2_0}
% 	% \end{subfigure}
% 	% \begin{subfigure}[t]{0.49\textwidth}
% 	\includegraphics[width=\textwidth]{chp04_paper_numerics/figures/gabc/S2_box_1.7320508075688772_1.4142135623730951_1_cropped}
% 	% \includegraphics[width=0.49\textwidth]{chp04_paper_numerics/figures/gabc/robust_box_1}
% 	% \caption{\(C = 1\)}
% 	% \label{fig:gabc_S2_1}
% 	\caption{The stochastic sensitivity field for the GABC flow \cref{eqn:gabc} with parameters \(A = \sqrt{3}\), \(B = \sqrt{2}\), and \(C = 1\), computed over the time interval \([0,3]\) on three faces of the cube \([0,2\pi] \times [0,2\pi] \times [0,2\pi]\).}
% 	\label{fig:gabc_S2}
% \end{figure}

\begin{figure}
	\begin{center}
		\includegraphics[width=0.3\textwidth]{chp04_paper_numerics/figures/gabc/S2_slices_yz_key}
		\includegraphics[width=0.3\textwidth]{chp04_paper_numerics/figures/gabc/S2_slices_xz_key}
		\includegraphics[width=0.3\textwidth]{chp04_paper_numerics/figures/gabc/S2_slices_xy_key}
		\caption{The arrangement of figures in \Cref{fig:gabc_S2}.}
		\label{fig:gabc_S2_key}
	\end{center}
\end{figure}

To introduce 3-dimensional noise to the system, we set \(\sigma = I\), the \(3 \times 3\) identity matrix, and compute stochastic sensitivity for a \(200\times 200\times 200\) grid of initial conditions on each face of the cube \([0,2\pi] \times [0,2\pi] \times [0,2\pi]\).
% \td{Check this with actual computations!}
% The spatial periodicity and symmetry of the dynamics means that these three faces are sufficient to describe the entire structure of the field within the region \citep{DombreEtAl_1986_ChaoticStreamlinesABC}.
As with the 2-dimensional example, for each initial condition we compute the \(3 \times 3\) covariance matrix using the Mazzoni method.
The stochastic sensitivity value is then again computed by taking the operator norm of this covariance matrix.
To visualise the three-dimensional structure of the field, in \Cref{fig:gabc_S2} we plot the stochastic sensitivity field on slices of the cube \([0,2\pi] \times [0,2\pi] \times [0,2\pi]\) in the arrangement given in \Cref{fig:gabc_S2_key}.

Within the vortices, the stochastic sensitivity value is smaller as there is a strong tendency for fluid trajectories to remain within each.
\td{Write this better. Can I explain why the uncertainty is larger in the jet-like part of the flow?}
The boundaries of the vortices are again highlighted by a sharp ridge of large stochastic sensitivity value.
In fact, these narrow ridge-like structures correspond to the unstable manifolds within the flow \citep{DombreEtAl_1986_ChaoticStreamlinesABC}: the repelling nature of these regions results in a `larger' stochasticity.



\begin{landscape}
	\begin{figure}
		\centering
		\includegraphics[width=0.42\textheight]{chp04_paper_numerics/figures/gabc/S2_slices_yz}
		\includegraphics[width=0.42\textheight]{chp04_paper_numerics/figures/gabc/S2_slices_xz}
		\includegraphics[width=0.42\textheight]{chp04_paper_numerics/figures/gabc/S2_slices_xy}
		\caption{The stochastic sensitivity field for slices of the GABC flow \cref{eqn:gabc}, following the order of \Cref{fig:gabc_S2_key}.}
		\label{fig:gabc_S2}
	\end{figure}
\end{landscape}
